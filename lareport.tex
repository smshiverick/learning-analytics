\documentclass[sigconf]{acmart}

\input{format/final}

\begin{document}
  \title{Modeling Student Performance for Data-Driven Learning Analytics}
  \author{Sean M. Shiverick}
  \affiliation{\institution{smshiverick@gmail.com}
  }
\renewcommand{\shortauthors}{S.M. Shiverick}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstract}

Predictive modeling approaches help researchers and educators identify patterns 
in education data and identify factors that influence student performance. This 
paper compares several models of student performance (linear regression, ridge
regression, the lasso, regression trees, random forests regression, gradient 
boosting) for features selection, feature importance and model interpretability. 
The student performance dataset consisted of N=1044 observations from two 
secondary schools in Portugal \cite{cortez08}. Performance was assessed by 
final grade (range; 0-20) in two courses, mathematics and Portugese. The models
were fit to a subset of training data and evaluated on a hold out testing set. 

The linear regression model revealed that plans for higher education, mother's 
education level, and weekly study time were positively associated with student 
performance, whereas course subject, school support, and romantic relations
were negatively related to performance. Non-linear trend in the data indicated
that tree-based models may better . 

All models identified as the most informative feature for predicting 
student performance. 

The models differed in the importance they assigned to

Advantages and limitations of the different models are  discussed. 
Model interpretation is an important aspect of predictive analytics.


\footnote{Address correspondence to \textit{smshiverick@gmail.com}.}

\end{abstract}
\keywords{Predictive Modeling, Supervised Learning, Variable Importance}
\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

Education institutions have generated very large amounts of data about student 
performance in recent decades due to dramatic increases in computing speed 
and processing power \cite{daniel15, daniel16}. The development and use of 
analytic approaches for predictive modeling allows researchers and educators  
to discover patterns in data and provide insights about learning for effective 
decision making. Educational data mining (EDM) and learning analytics (LA) are 
multidisciplinary fields at the intersection of learning science, social science, 
statistics, and computer science that leverage big data to understand learning 
and the environments in which it occurs \cite{siemens13, siemensbaker12}. 
Predictive modeling provides useful methods for analyzing the factors that 
contribute to student success and identifying individuals at risk for failure
or dropping out. This study reviewed EDM and LA findings and compared several 
supervised learning models with sample data to determine which approach is 
best for modeling student performance and success. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The fields of LA and EDM both share the goal of using research methods and
predictive analysis to improve student performance and instructional design 
\cite{baker09, ferguson12, lester19}. EDM research has focused more on the 
technical challenges of extracting value from big data in education 
\cite{penaAyala14, romero10}, whereas LA takes a more holistic, education-
focused approach to learning to inform and empower instructors and learners 
\cite{lang17, papamitsiou14}. Despite differences in their respective origins 
and emphasis, LA and EDM are complementary approaches that use similar 
methodologies. Together, LA and EDM represent an ecosystem of techniques for 
gathering, processing, and acting on data to promote learning. These procedures 
facilitate the preparation, measurement, and collection of data about learning 
activities for subsequent analysis, interpretation, and reporting. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Historically, education institutions have tracked student performance, 
dropout, and retention and used analytic tools to identify factors important 
for learning such as persistence and social integration \cite{ferguson12}. 
As extensive education datasets became available for analysis, LA/EDM 
researchers have applied a diverse range of descriptive, correlational, and 
predictive methodologies to discover potentially useful patterns in data for 
understanding students and the contexts in which they learn. Student 
characteristics are often modeled in terms of domain knowledge, motivation, 
metacognitive abilities (i.e., thinking about thinking), learning strategies, 
attitudes, and affect \cite{papamitsiou14}. The main analytic approaches used 
in EDM/LA research include discovery with models (i.e., predictive modeling), 
similarity grouping, relationship mining, content analysis, and social network 
analysis (SNA) \cite{baker09}. This paper focues on predicting modeling of
student performance as a form of data-driven learning analytics
\cite{verbert12}. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Predictive Modeling}

Predictive modeling involves a set of procedures and automated processes for 
extracting knowledge from data \cite{jamesetal13, kuhn13}. The two main 
branches of predictive modeling are supervised learning and unsupervised 
learning. Supervised learning problems involve prediction about a specific 
outcome or target variable (i.e., course grade) when examples of input/output 
pairs are available in the data. If a dataset has no target outcome, 
unsupervised learning methods (e.g. clustering) can reveal structure in 
unlabeled data. Clustering can be used to group individuals together based 
on similar learning profiles. In this study, student performance is analyzed
as a supervised learning problem based on final course grades. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Two main approaches for supervised learning problems are classification and 
regression. For a binary or categorical outcome represented as a class label 
(i.e., `pass`/`fail`), a classification model will predict which class or 
category that new instances are assigned to. When the target variable to be 
predicted is measured on a continuous scale (e.g. GPA), a regression model 
tests how a set of attributes or features predicts the target outcome. 
Classification is the most commonly used data analytic methods for modeling 
students and their behavior, and can include methods such as logistic 
regression, support vector machines, naive Bayes, decision trees, and 
neural networks \cite{Lykourentzou09, pariyadath14, zhang05}. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The present study compares several regression models of student performance 
to identify the set of features that best predict student performance. Each 
model is trained on a set of input-output pairs and then used to make 
predictions about new observations that were previously set aside. Comparing 
different predictive models can help determine which model is best for a given 
problem with the data available \cite{raschka17}. Past empirical findings 
indicate that, in addition to course assessments (i.e., number of quizzes 
passed), student engagement and participation in course activities are the most 
influential predictors of final grades \cite{Papamitsiou14, romerozaldivar12}. 
A student's sense of belonging is essential for engagement and improved course 
satisfaction, which in turn can reduce student dropout rate. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{General Linear Model} 

A general assumption of linear regression models is that the target outcome
can be represented as a linear function of the input features. The standard 
linear model (below) describes the relationship between predicted target 
variable (Y) from a set of features ($X_1$ ... $X_p$), including some measure 
of error (e). The predicted value of the target outcome can be thought of as 
the weighted sum of the input features with the weights or coefficients 
(i.e., beta values) indicating the influence of a given feature on the outcome. 
Ordinary least squares (OLS) regression miminizes the distance (i.e., error) 
between the predicted values of Y and the observed values in the dataset. 
If the number of observations (\textit{n}) is much larger than the number of 
features (\textit{p}), OLS coefficient estimates will have low variance and 
perform well on test observations; however, if the number of observations 
\textit{n} is not much larger than the number of features \textit{p}, high 
variability in the OLS fit can result in overfitting and poor prediction on 
the test observations. For high-dimensional datasets (\textit{$p>>n$}), 
the least squares coefficient estimate breaks down. The simple linear model 
can be improved by using alternative fitting approaches that produce better 
prediction accuracy and model interpretability \cite{jamesetal13}. 

\begin{equation}
  \ Y = \beta_0 + \beta_1X_1 + \beta_2X_2 +... + \beta_pX_p + \epsilon
\end{equation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Feature Selection} 

In many regression analyses, it is often the case that multiple independent 
variables or features will not be correlated with the target outcome. Three 
methods for improving the fit of linear models are: (a) subset selection, 
(b) dimension reduction, and (c) regularization (i.e.., shrinkage. Determining 
which set of features is best for representing the predicted outcome is 
essential. A straight forward approach to feature selection is to conduct a 
regression including all the independent variables and then to rerun the 
regression excluding the non-significant variables from the model.
Another approach termed regularization includes all \textit{p} predictor 
variables, but constrains (i.e., `regularizes`) the coefficient estimates of 
the independent variables by shrinking them towards zero. Regularization 
reduces variablity, which in turn improves test set accuracy with a slight 
increase in bias. Shrinking the coefficient estimates of irrelevant features 
toward zero reduces overfitting and provides a more interpretable model. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Regularization} 

\textbf{Ridge Regression: L2 Penalty} 

As with OLS, ridge regression seeks coefficient estimates that fit the data 
well by reducing error, but ridge regression introduces a shrinkage penalty
(L2) that has the effect of shrinking the coefficient estimates towards zero. 
When the tuning parameter (lambda) is set to zero, the shrinkage penalty has 
no effect and ridge regression produces the least squares estimates. As the 
value of lambda increases, the estimated regression coefficients approach zero 
\cite{statlearn13}. The advantage of ridge regressions over least squares is 
based on the bias-variance tradeoff. As the tuning parameter lambda increases, 
the flexibility of the ridge regression decreases, leading to decreased variance 
but increased bias. Lower variance is associated with reduced overfitting, 
whereas higher bias can lead the model to miss relevant relations between
features and target outputs (underfitting). Ridge regression is often applied 
after standardizing the predictor variables so that they are all on the same 
scale (e.g., \textit{M}=0, \textit{SD}=1). Ridge regression performs well with
high-dimensional datasets (p>>n) by trading off a small increase in bias for a 
large decrease in variance. A disadvantage of ridge regression is that, because 
it includes all predictors in the model, the penalty shrinks the coefficients 
toward zero, but does not set any of them exactly to zero. This can create a 
problem for model interpretation with a dataset that has a very large number
of features. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{The Lasso: L1 Penalty} 

The lasso and ridge regression have similar formulations, but the lasso has 
a major advantage over ridge regression as it produces simpler, more 
interpretable models based on a subset of features. The lasso uses the L1 
penalty which has the effect of forcing some of the coefficient estimates to be
equal exactly to zero when the tuning parameter lambda is sufficiently large 
\cite{statlearn13}. Thus, the lasso performs variable selection, and produces 
sparse models based on a subset of the features, which are generally easier to 
interpret than ridge regression. The lasso implicitly assumes that a number of 
the feature coefficients or weight truly equal to zero. In general, the lasso 
performs better than ridge regression in situations where a small number of 
features account for most of the variability in the target outcome, and the 
remaining features have coefficients that are very small or equal to zero. 
By contrast, ridge regression performs better when the target is a function 
of a large number of predictors that contribute approximately equally to the
coefficients. Cross-validation can be used to determine the optimal value
of the parameter lambda and also which approach is better. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Decision Tree Models}

\textbf{Regression Trees}
Decision tree models are widely used for classification and regression. Tree 
models are built on a hierarchy of \textit{if-else} questions that proceeds 
from a root node as the starting point and continues through a series of 
decisions. Each node in the tree represents either a question or a terminal 
node (i.e.,leaf) that contains the outcome. In constructing the tree, the 
algorithm searches through all possible decisions or tests, and finds a 
solution that is most informative about the target outcome. The recursive 
branching process of tree based models yields a binary tree of decisions, 
with each node representing a test that considers a single feature. This 
process of recursive partitioning is repeated until each leaf in the decision 
tree contains only a single target. Prediction for a new data point proceeds 
by checking which region of the partition a new point falls into, and 
predicting the majority in that feature space. Tree based models require 
little adjustment and are easy to interpret. A drawback is that they can lead 
to very complex models that highly overfit data used to train the model. A 
good strategy for building a regression tree is to grow a very large tree 
and then prune it back to obtain a subtree that provides the lowest test error 
rate. A good way to prevent overfitting is to use pre-pruning to limit 
the maximum depth of the tree. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\textbf{Random Forest Regression}

A random forest is a collection of decision trees that are slightly different 
where each tree overfits the data in a different way. This approach reduces 
overfitting by building many trees and averaging their results. Randomness is 
introduced into the tree building process in two ways: first, by drawing a 
random subset (i.e., bootstrap sample) of the data, and second by selecting 
a random subset of features at each node branch \cite{breiman01}. In building 
the random forest, the user must first decide how many trees to build and the 
algorithm makes different random choices so that each tree is distinct
\cite{muller17, raschka17}. The bootstrapping method repeatedly draws random 
samples of size \textit{n} from the dataset with replacement. The decision 
trees are built on these random samples that are the same size as the original 
data, with some points missing and some data points repeated. The algorithm 
also selects a random subset of p features, that are repeated separately at 
each node, so that each decision at the node branch is based on a different 
subset of features. These two processes help ensure that all of the decision 
trees in the random forest are different. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Gradient Boosting}

Gradient boosting is an ensemble approach that builds many smaller trees,  
where each new tree attempts to correct for deficiencies of the current 
ensemble. In contrast to randome forests, gradient boosting grows smaller, 
stubbier trees, and goes after bias. \cite{jamesetal13, kuhn13}. Gradient 
boosted regression trees use strong pre-pruning, with shallow trees of a 
depth of one to five; thus, each tree provides an estimate of part of the 
data. Combining many shallow trees iteratively improves model performance. 
Gradient boosting and random forests perform well on similar tasks and data. 
A common practice is to first construct random forests and then use gradient 
boosting to improve model accuracy \cite{muller17}. 

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{table*}[ht]
  \caption{Variables in the Student Performance Dataset \cite{cortez08}}
  \label{tab:freq}
  \begin{tabular}{ll}
    \toprule
    \textit{Target Variable} &  \\
    \midrule
    Final course grade (0=Lowest, 20=Highest) & G3 \\
    \midrule
    \textit{Predictor Variables} &    \\
    \midrule
    1. Sex (0=Male,1=Female) & SEX  \\  
    2. Age (15, 16, 17, 18, 19+ years) & AGE  \\
    3. Home address type (0=Rural, 1=Urban) & AREA  \\
    4. Family size (0=Three or less, 1=More than three) & FAMSIZE  \\
    5. Parents' cohabitation status (0=Separate, 1=Together) & PARENTS  \\ 
    6. Mother's education (0=None, 1=Primary, 2=Grades 5-9,  3=Secondary, 4=Higher education) & MEDU  \\
    7. Father's education (0=None, 1=Primary, 2=Grades 5-9,  3=Secondary, 4=Higher education) & FEDU  \\
    8. Mother's job (0=At home, 1=Other, 2=Civil Services, 3=Health Care, 4=Teacher) & MJOB  \\
    9. Father's job (0=At home, 1=Other, 2=Civil Services, 3=Health Care, 4=Teacher) & Fjob  \\
    10. Student's guardian (0=Other, 1=Father, 2=Mother) & Guardian  \\
    11. Time from home to school (1=<15 min, 2=15-30 min, 3=30-60 min, 4=>60 min) & TRAVEL  \\
    12. Weekly study time (1=<2 hours, 2=2-5 hours, 3=5-10 hours, 4=>10 hours) & STUDY  \\
    13. Extra educational support (0=No, 1=Tes) & SCHOOLSUP  \\
    14. Family educational support (0=No, 1=Tes) & FAMSUP  \\
    15, Paid extra subject classes (0=No, 1=Tes) & PAID  \\
    16. Extra-curricular activities (0=No, 1=Tes) & ACTIVITIES  \\
    17. Wants to take higher education (0=No, 1=Yes) & HIGHER  \\
    18. Internet access at home (0=No, 1=Tes) & INTERNET  \\
    19. In a romantic relationship (0=No, 1=Tes) & ROMANTIC  \\
    20. Quality of family relationships (1=Very Bad, 5=Excellent) & FAMREL  \\
    21. Free time after school (1=Very Low, 5=Very High) & FREETIME  \\
    22. Going out with friends (1=Very Low, 5=Very High) & GOOUT  \\
    23. Workday alcohol consumption (1=Very Low, 5=Very High) & DALC  \\
    24. Weekend alcohol consumption (1=Very Low, 5=Very High) & WALC  \\
    25. Current health status (1=Very Bad, 5=Very Good) & HEALTH  \\ 
    26. Number of school absences (Count range: 0 to 93) & ABSENCES  \\
    27. Course subject (0=Portugese, 1=Mathematics) & COURSE  \\
    \bottomrule
  \end{tabular}
\end{table*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Project Goals} 

The project examines the relationships between student characteristics,  
behavior, and performance. Data on student performance was obtained from two 
secondary schools in Portugal \cite{cortez08}. The dataset included information
collected from a student survey and school grade records. The data were fit
using several supervised machine learning models (described above) to identify 
the set of features that best predicted student success and characteristics 
associated with course failure. The target variable was final course grade in 
two courses, mathematics and Portugese. The predictors variables of interest 
were demographic variables, family characteristics, and student behaviors 
(e.g., weekly study hours). This method can help to explore important factors 
that contribute to student performance by: (i) Identify demographic factors 
related to students success and failure, (ii) Identify associations between 
students performance and the independent variables, (iii) Identify which model
provides the most accurate and interpretable solution. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Method}

\subsection{Data}

The student performance dataset was downloaded from the UC-Irvine machine 
learning repository (UCI-MLR) and saved as a data frame object in a python 
interactive notebook. The data was collected from two secondary schools in 
the Alentejo region of Portugal during the 2005-2006 school year and 
contained information from a questionnaire and school reports of student 
grades \cite{cortez08}. The sample consisted of 1044 students (56.6\% female, 
\textit{M} age=16.71 years, \textit{SD}=1.19, \textit{Median}=17 years, 
\textit{range}=15-22). Age was measured as a categorical variable 
(\textit{n}=10 individuals between 20 to 22 years were included in the 19+ 
years group). The dataset consisted of thirty independent variables, 
including demographic information, social/ emotional attributes, school-
related variables, and student behaviors (see Table 1). The target variable, 
Student performance was evaluated on a 20 point scale--as in other European 
countries (e.g., France)--at three points during the school year (i.e., 
Grade1, Grade2, Grade3) for two courses (Mathematics n=395; Portugese, n=649). 
The target variable of interest was the final course grade. A binary dummy 
variable of student performance was calculated based on the measure of final 
exam grades (Pass$>$10, Fail$<=$10) for descriptive purposes.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Model Construction}

\subsubsection{Linear Regression (OLS)} 

All models were constructed in R (using Rstudio) following examples from
James, Witten, Hastie, and Tibshirani (2013), \emph{An Introduction to 
Statistical Learning with Applications in R}\cite{jamesetal13}. After 
preliminary exploration of the data, the sample was divided into the training 
set ($n_1$=731) and testing set ($n_2$=313) using a 70 to 30 percent split. 
Each model was first fit to training data and evaluated on the testing set. 
Student performance was regressed on 27 independent variables shown in Table 1 
using the general linear model (OLS). The regression model was run on the 
training set with the full set of predictor variables; the model was then 
rerun excluding all non-significant predictors variables from model. The final 
model was then evaluated on the testing set. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Ridge regression (L2 penalty)} 

The glmnet package was used to fit the ridge regression and lasso models. 
The glmnet() function does not use model formula language (i.e., y \~\ x), 
so the X matrix of predictors and target vector Y were passed to the model. 
The `model.matrix()` function produced a matrix corresponding to the 27 
predictors and automatically transformed any qualitative variables into
dummy variables. The `alpha` parameter in the glmnet() function determines 
what kind of model is fit: alpha=0 is used to fit ridge regression. It is
important to select an appropriate value of the parameter lambda, as the
algorithm generates a different set of coefficients for each value of 
lambda. By default, the glmnet() function performs ridge regression for an 
automatically selected range of lambda values (e.g., 100). The glmnet 
function also standardizes the variables so they are all on the same scale.
The shrinkage penalty is applied to every feature, but not the intercept. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{The Lasso (L1 Penalty)} 
 
The Lasso model was fit using the glmnet() function with alpha=1. The model 
automatically calculates correlation estimates for a wide range of lambda 
values. Cross-validation was used to select an optimal value of the tuning 
parameter lambda. The lasso is similar to best subset selection as it tries 
to find the set of coefficient estimates that leads to the smallest error (RSS). 
In terms of the bias-variance tradeoff, the lasso is qualitatively similar to 
ridge regression. As lambda increases, the variances decreases and bias 
increases somewhat; however, the variance of ridge regression is slightly 
lower than the variance of the lasso. 
 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Regression Trees} 

The regression tree model of student performance was fit to the training data 
using the rpart() function in R, with all 27 independent variables. The decision
tree uses recursive binary splitting to constructed to grow a large tree on the 
training data. Cross-validation was used to determine the optimal tree complexity.
The model was prepruned to a maximum depth of 3, which means the algorithm split 
on three consecutive features.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Random Forests Regression} 

The random forest model was fit using 1000 trees, with all of the features 
considered at each node to determine the randomness of each tree. In general,
random forests work well without very much parameter tuning or scaling of data. 
The important parameters for the random forests algorithm are the number of 
sampled data points and the maximum number of features; the algorithm can 
look at all of the features in the dataset or a limited number. A high value 
for \emph{maximum-features} will produce trees in the random forest that are 
very similar and will fit the data easily based on the most distinctive features, 
whereas a low value will produce trees that are very different from each other, 
and reduces overfitting. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Gradient Boosted Model} 

In addition to pre-pruning and the number of trees, an important parameter 
for gradient boosting is the \emph{learning rate} which determines how 
strongly each tree tries to correct for mistakes of previous trees. A high 
learning rate produces stronger corrections, allowing for more complex models. 
The gbm package ("Gradient Boosted Machines", Friedman) was loaded, and the 
gbm() function was called on student performance (final grade) using the 
Gaussian distribution, with 1000 shallow trees, a shrinkage parameters=0.01, 
and interaction depth of 4 splits. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{table}
  \caption{Correlation Matrix of Previous Course Failures and Course Grade 
  Variables}
  \label{tab:freq}
  \begin{tabular}{lllll}
    \toprule
    Variable    & Failures  & Grade 1 & Grade 2 & Grade 3  \\
    \midrule
    Failures    &  1,00     &  0.37***  & 0.38***   &  0.38***  \\
    Grade 1     &  0.37***  &  1,00     & 0.86***   &  0.81***  \\
    Grade 2     &  0.38***  &  0.86***  & 1.00      &  0.91***  \\  
    Grade 3     &  0.38***  &  0.81***  & 0.91***   &  1.00     \\    
    \bottomrule
    Note. *** \textit{p}$<$0.001 & & &
  \end{tabular}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\begin{figure}[!ht]
  \centering\includegraphics[width=\columnwidth]{images/Figure1.pdf}
  \caption{Proportion of Passing or Failing Final Grades as a 
  Function of Previous Course Failures}
  \label{f:Figure1}
\end{figure} 
 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
 
 
\begin{table}
  \caption{Summary Table of Student Performance by Final Course Grade 
  (Pass$>=$10, Fail$<$10) for Selected Variables}
  \label{tab:freq}
  \begin{tabular}{llllll}
    \toprule
                    &  \textbf{Pass} & & & \textbf{Fail} & \\
    Attribute & \textit{N} & \% &  & N & \% \\
    \midrule
    \textbf{Total}  & 661 & 63.3\% & & 383 & 36.7\% \\
    \midrule
    Male            & 277 & 61.1\% & & 176 & 38.9\%  \\
    Female          & 384 & 65.0\% & & 207 & 35.0\%  \\
    \midrule
    \textbf{Course} &  &  &  &  & \\
    Portugese       & 452 & 69.6\% & & 197 & 30.4\%  \\
    Math            & 209 & 52.9\% & & 186 & 47.1\%  \\  
    \midrule
    \textbf{Mother's Education} &  &  &  &  & \\
    Higher Ed       & 235 & 76.8\% & &  71 & 23.2\% \\
    Secondary       & 143 & 49.5\% & &  95 & 32.9\% \\
    Grades 5 to 9   & 180 & 75.6\% & & 109 & 45.8\% \\
    Primary         &  98 & 47.5\% & & 106 & 52.5\% \\
    None            &   7 & 77.8\% & &   2 & 22.2\% \\
    \midrule   
    \textbf{Higher Education Plans} &  &  &  &  & \\
    Planned         & 640 & 67.0\% & & 315 & 33.0\%  \\
    No Plans        &  21 & 23.6\% & &  68 & 76.4\%  \\
    \midrule
    \textbf{School Support} &  &  &  &  & \\
    Received        &  63 & 52.9\% & &  56 & 47.1\%  \\
    None            & 598 & 64.6\% & & 327 & 33.4\%  \\ 
    \midrule    
    \textbf{Study Time} &   &  &  &  &     \\
    More than 10 hrs. &  45 & 72.6\% & &  17 & 27.4\% \\
    5 to 10 hrs.      & 123 & 75.9\% & &  39 & 24.1\% \\
    2 to 5 hrs.       & 321 & 63.8\% & & 182 & 36.2\% \\    
    Less than 2 hrs.  & 172 & 54.3\% & & 145 & 45.7\% \\
    \midrule
    \textbf{Romantic Relationship} & &  &  &  & \\
    Yes             & 221 & 59.6\% & & 150 & 40.4\%  \\    
    None            & 440 & 65.4\% & & 233 & 34.6\%  \\
    \midrule
    \textbf{Internet Access} & &  &  &  & \\
    Yes             & 543 & 65.7\% & & 284 & 34.3\%  \\    
    None            & 118 & 54.4\% & &  99 & 45.6\%  \\
    \bottomrule
  \end{tabular}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\begin{table*}[ht]
  \caption{Coefficient Estimates for Regression Models of Student Performance on 
  Training Set and Testing Set}
  \label{tab:freq}
  \begin{tabular}{lllllll}
    \toprule
                        & Training Set      &        &         & Testing Set &         &          \\
    \midrule
    Variables           & Coefficient        & S.E.  & t-value & Coefficient & S.E. & t-Value  \\
    \midrule
    Intercept           &       13.289***    & 2.166 &  6.14  &          6.955*     & 3.629 &  1.92 \\
    Course              & \textbf{-2.225}*** & 0.261 & -8.53  & \textbf{-1.162}***  & 0.445 & -2.61 \\
    Mother's Education  & \textbf{ 0.485}*** & 0.122 &  3.97  & \textbf{ 0.473}**   & 0.213 &  2.25 \\
    Go Out with Friends & \textbf{-0.442}*** & 0.114 & -3.89  &         -0.097      & 0.178 & -0.55 \\
    Higher Ed           & \textbf{ 1.695}*** & 0.487 &  3.48  & \textbf{ 4.101}***  & 0.772 &  5.31 \\    
    School Support      & \textbf{-1.435}*** & 0.416 & -3.45  & \textbf{-1.481}**   & 0.647 & -2.29 \\
    Health              & \textbf{-0.262}*** & 0.088 & -2.97  &         -0.008      & 0.152 & -0.05 \\
    Study Time          & \textbf{ 0.454}*** & 0.156 &  2.91  & \textbf{ 0.893}***  & 0.260 &  3.43 \\
    Internet Access     & \textbf{ 0.819}**  & 0.321 &  2.55  &          0.420      & 0.542 &  0.77 \\
    Family Relations    & \textbf{ 0.340}**  & 0.140 &  2.43  &         -0.096      & 0.215 & -0.45 \\
    Romantic Relation   & \textbf{-0.600}**  & 0.266 & -2.26  & \textbf{-1.127}**   & 0.461 & -2.45 \\
    Age                 & \textbf{-0.250}**  & 0.114 & -2.20  &         -0.034      & 0.191 & -0.18 \\
    Family Size         & \textbf{-0.500}*   & 0.278 & -1.80  &         -0.594      & 0.458 & -1.30 \\
    Father's Job        & \textbf{ 0.278}*   & 0.145 &  1.92  &         -0.050      & 0.245 & -0.20 \\
    \midrule
    \textit{n}          &       730          &       &        &         314         &       &       \\
    \textit{F-Value}    & \textbf{15.41}***  &       &        & \textbf{5.96}***    &       &       \\
    \textit{df}         &   (13, 716)        &       &        &      (13, 300)      &       &       \\
    \textit{$R^2$}      &      0.219         &       &        &         0.205       &       &       \\ 
    \textit{Adj. $R^2$} &      0.204         &       &        &         0.171       &       &       \\
    \textit{Resid. S.E} &      3.396         &       &        &         3.643       &       &       \\
    \bottomrule
    Note. Significance levels & *$<$0.10      & **$<$0.05  & ***$<$0.01 & & &
  \end{tabular}
\end{table*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\section{Results}

\subsection{Exploratory Data Analysis}

Preliminary examination of the data revealed significant correlations 
between previous course failures and the course evaluation variables,
Grade 1, Grade 2, and Grade 3 (Table 2). A chi-squared test of independence 
showed the proportion of passing and failing final grades (G3) was 
significantly related to previous course failures ($\chi 2$ ,
\textit{p}$=$0.001)(Figure 1). The majority of students with no past failures 
successfully passed their courses, but only a minority of students with one
or more previous failures received a passing grade. Past course failures 
and the first two course grades (i.e., Grade 1, Grade 2) were not included 
in the regression models to address the issue of multicolinearity.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Table 3 provides descriptive statistics for selected attributes. Chi-squared 
tests of independence were used to compare the proportion of students who 
received passing and failing grades by attribute. There was no relationship
between performance and sex; males and females did not differ significantly 
in performance ( $\chi 2$ , \textit{p}$=$0.20). Student performance did vary
according to mother's level of education ($\chi 2$ , \textit{p}$<$0.05), but 
as seen in Table 3, the relationship between performance and mother's 
education was non-linear. Performance did vary significantly by course 
topic ($\chi 2$ , \textit{p}$<$0.001); more than two-thirds of students in the 
Portugese course successfully passed, whereas just over half of students in 
the mathematics course received a passing grade. The relationship between 
students' performance and their plans for higher education was also significant 
($\chi 2$ , \textit{p}$<$0.001). Two-thirds of students with plans to pursue 
higher education received a passing grade, whereas less than one-quarter of 
students with no plans for higher education passed their courses. Extra 
educational school support was also significantly related to performance 
($\chi 2$ , \textit{p}$<$0.001). Just over half of students who received 
extra educational support at school received a passing grade compared to 
nearly two-thirds of students who did not receive extra support. 

As expected, weekly study time was significantly associated with student 
performance ($\chi 2$ , \textit{p}$<$0.001). The proportion of passing and 
failing grades significantly different for students who studied 5 hours or 
more per week compared to students who studied less than 5 hours per week. 
The association between romantic relationships and student performance 
was marginally significant ($\chi 2$ , \textit{p}$<$0.06). The proportion 
of passing and failing grades was significantly different for students in 
a romantic relationship than students not in a romantic relationship. The 
relation between internet access and student performance was also marginally 
significant ($\chi 2$ , \textit{p}$<$0.06). The proportion of passing and
failing grades was significantly different for students with access to the 
internet at home compared to students without home internet access 
($\chi 2$ , \textit{p}$<$0.05).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Linear Regression and Regularization}

\subsubsection{General Linear Model}

Student performance was first regressed on the 27 independent variables 
(Table 1) with the training set; this regression was statistically 
significant and accounted for 19.7\% of the variance in the predicted
value of student performance, taking into account the number of 
independent variables, \textit{F}(27, 702) = 7.62, \textit{p} $<$ 0.001 
($R^2$=0.227, adjusted $R^2$=0.197). The regression model was rerun, 
excluding the non-significant predictors, and this regression also 
yielded a significant relationship between student performance and the 
independent variables, accounting for 20.4\% of the variability in 
predicted performance, \textit{F}(12, 717) = 21.79, \textit{p} $<$ 0.001 
($R^2$=0.219, adjusted $R^2$=0.204). An ANOVA test showed no significant 
difference between the two models (\textit{F}$<$ 1.0, \textit{p} $=$ 0.91) 
and the simpler model with thirteen predictor variables was retained as the 
final model. The estimated coefficients, standard error, and t-value on the 
testing set (ranked by t-Value) are presented in the left side of Table 3.

%\begin{equation*}
% \begin{aligned}
%   Y = 13.29 - 2.23(Course) - 1.44(SchoolSupp) + 1.70(HighEd) - \\
%   (0.44GoOut) + 0.49(MotherEd) -0.26(Health) + \\
%   0.45(StudyTime) + 0.34(FamilyRelations) - 0.25(Age) - \\
%   0.60(RomanticRel) + 0.82(Internet) - \\
%   0.50(FamilySize) + 0.278(FatherJob) 
% \end{aligned}
%\end{equation*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The final model was evaluated on the testing set and the regression yielded 
a significant relationship between student performance and the independent 
variables, accounting for 17.1\% of the variability of the predicted value 
of student performance, taking into account the number of independent 
variables, \textit{F}(13, 300) = 5.96, \textit{p} $<$ 0.001 ($R^2$=0.205, 
adjusted $R^2$=0.171). As shown in Table 3, 6 of the 13 independent
variables in the testing set were significant, which suggests that the 
model was overfit to data in the training set, The predicted values of
student performance are be explained by the combined effect, or 
weighted average, of the coefficient estimates and the observed values 
for each significant independent variable in the model (Equation 2).

\begin{equation*}
 \begin{aligned}
  Y = 6.955 - 1.162(Course) 0.473(MotherEd) + 4.101(HighEd) + 0.893(StudyTime) \\
    - 1.481(SchoolSupport) - 1.127(RomanticRelation) \\
 \end{aligned}
\end{equation*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

On the testing set, there was a 1.16 decrease in predicted performance 
for students in the math course compared to students in the Portugese course, 
controlling for all other independent variables. A unit change in mother's 
level of education was associated with a 0.47 increase in predicted student 
performance, controlling for all other variables. Students with plans to pursue
higher education had a 4.10 higher predicted final grade than students with 
no plans for higher education, controlling for other variables. A one-unit 
change in weekly study time resulted in a 0.89 increase in predicted student 
performance, holding constant the effect of other variables. Students receiving 
school support had a 1.48 lower predicted final course grade than students who 
did not receive school support, holding all other variables constant. Finally, 
there was a -1.13 decrease in predicted performance for students in a romantic 
relationship compared to students not in a romantic relationship, controlling
for all other independent variables. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[!ht]
  \centering\includegraphics[width=\columnwidth]{images/Figure2.pdf}
  \caption{Coefficient Estimates for the Ridge Regression model 
  (L2 Penalty) as a function of the log Values of Lambda}
  \label{f:Figure2}
\end{figure}

\begin{figure}[!ht]
  \centering\includegraphics[width=\columnwidth]{images/Figure3.pdf}
  \caption{Coefficient Estimates for the Lasso Regression model 
  (L1 Penalty) as a function of the log Values of Lambda}
  \label{f:Figure3}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\begin{table}
  \caption{Coefficient Estimates for Ridge Regression and the Lasso Model of 
  Student Performance using Best Value of Lambda from Cross-Validation}
  \label{tab:freq}
  \begin{tabular}{lll}
    \toprule    
                        &   Ridge (L2 Penalty)  & Lasso (L1 Penalty) \\
    \midrule
    Best lambda (CV)    &    0.819      &  0.071    \\
    MSE                 &   13.779      & 13.895    \\
    \midrule
    \textit{Predictor Variables}  & \textit{Coefficients} &  \textit{Coefficients} \\
    \midrule
    Intercept           &   13.498      &   12.899   \\
    Course              &   -1.801      &   -2.058   \\
    Higher Ed           &    1.390      &    1.534   \\
    School Support      &   -1.148      &   -1.121   \\
    Internet Access     &    0.602      &    0.614   \\
    Romantic Relation   &   -0.487      &   -0.461   \\    
    Family Size         &   -0.447      &   -0.353   \\   
    Study Time          &    0.345      &    0.353   \\   
    Mother's Education  &    0.326      &    0.403   \\    
    Going Out           &   -0.280      &   -0.316   \\
    Family Relations    &    0.274      &    0.247   \\
    Family Support      &   -0.258      &   -0.152   \\ 
    Area (Urban/Rural)  &    0.242      &    0.192   \\
    Age                 &   -0.223      &   -0.196   \\ 
    Father's Job        &    0.209      &    0.205   \\
    Health              &   -0.203      &   -0.199   \\
    Weekly Alcohol Cons.&   -0.130      &   -0.113   \\
    Mother's Job        &    0.127      &    0.066   \\
    Travel Time to School & -0.109      &   -0.053   \\
    Parents Rel. Status &    0.258      &    0.045   \\   
    Daily Alcohol Cons. &   -0.072      &   -0.029   \\ 
    Sex                 &    0.118      &    0.   \\
    Paid Extra Classes  &   -0.050      &    0.   \\      
    Extra Activities    &    0.015      &    0.   \\    
    Free Time           &   -0.062      &    0.   \\    
    Absences            &    0.002      &    0.   \\
    Father's Education  &    0.046      &    0.   \\         
    Student Guardian    &   -0.052      &    0.   \\    

    \bottomrule
  \end{tabular}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\subsubsection{Ridge Regression (L2 Penalty)}

Figure 2 plots the coefficient estimated from the ridge regression model (L2) 
as a function of the log values of lambda (x-axis). As the values of lambda 
become very large, the model shrinks the coefficient values of non-relevant 
predictor variables towards zero, but the values are never exactly equal to 
zero. Cross-validation was used to obtain the best value of lambda, which 
was, $\lambda$ = 0.819 (ln$\lambda$  = -0.200). As shown in Figure 2, the 
predictors with the highest coefficient values were course subject (27), 
students' plans for higher education (17), extra school support (13), and 
internet access at home (18). The ridge regression (L2) was rerun using the
best value of lambda from cross-validation with all 27 predictor variables 
with coefficient estimates shown in Table 5. The ridge regression model had 
a mean squared error (MSE) of 13.78. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{The Lasso (L1 Penalty)}

Figure 3 plots the estimated coefficients from the lasso (L1) regression as 
a function of the log value of lambda, with the number of associated features 
listed across the top of the plot. The plot shows that as the values of lambda 
increase, the L2 penalty shrinks many of the coefficient values to be equal 
exactly to zero. Cross-validation was used to obtain the best value of lambda, 
$\lambda$ = 0.071 (ln$\lambda$)= -2.65). The lasso model was rerun using the 
optimal value of lambda selected by cross validation with 20 predictor 
variables; the model had a mean squared error (MSE) of 13.895 and accounted 
for approximately 20 percent of the variability in student performance. 
Similar to the ridge regression, the predictors with the highest coefficients 
were course subject (27), plans for higher education (17), extra school support 
(13), and internet access at home (18). The error from the lasso model is very 
similar to the ridge regression, but the lasso has an advantage over ridge 
regression in that the resulting coefficient estimates are sparse and the 
model selected a subset of the predictor variables. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Decision Tree Models}

\begin{figure}[!ht]
  \centering\includegraphics[width=\columnwidth]{images/Figure4.pdf}
  \caption{Regression Tree Model of Student Performance on the 
  Traing Set (\textit{n}=700)}
  \label{f:Figure4}
\end{figure}

\subsubsection{Regression Trees}

The decision tree model was fit to the training set, with a maximum depth of 3;
Figure 4 shows the resulting regression tree with course subject as the root 
node and 7 terminal nodes. Course subject was a dummy variable; the branch to 
the left represents students in the mathematics course (39\%) and the branch to 
the right represents students in the Portugese course (61\%). In addition to 
course subject, the algorithm split on mother's education level, weekly study 
time. student absences, and age in constructing the tree. The values of student 
performance ranged from 5, for students in the mathematics course with no 
absences who were 18 years or older, to 13 for students in the Portugese course 
whose mother's had some higher education. The regression tree model was evaluated 
on the test set (maximum depth=3) which yielded a tree with plans for higher 
education (rather than course subject) as the root node and 6 terminal nodes 
(see Figure 5). The MSE for the regression tree on the testing set was 16.385.

\begin{figure}[!ht]
  \centering\includegraphics[width=\columnwidth]{images/Figure5.pdf}
  \caption{Regression Tree Model of Student Performance on the
  Testing Set (\textit{n}=314)}
  \label{f:Figure5}
\end{figure}

As seen in Figure 5, from the root node of plans for higher education, the 
algorithm split at nodes for mother's education level, area (urban / rural),
course subject, and student absences in constructing the tree. Following 
the right branch from the root node, students with plans for higher education 
(91\%) had a mean predicted performance of 12, whereas on the left branch, 
students with no plans for higher education (9\%) had a mean predicted
performance of only 7. For students with plans for higher education, the next 
split on mother's education level: Following the branch to the right, students 
whose mothers had 5th grade level of education or higher (74\%) had a mean 
predicted performance of 12. Following this branch to the next node of area, 
on the rigth branch students in urban areas (55\%) had a mean predicted
performance of 13, whereas students in rural areas (19\%) had a mean 
performance of 11. On the left branch, students whose mother's had attended 
secondary school or lower (17\$), the mean predicted performance was 10. This 
branch split next on course topic, and students in the Portugese course (12\%) 
had a mean predicted performance of 11, whereas the mean performance for 
students in the mathematics course (5\%) was 8.2. For students with no plans for 
higher education (9\%), the next node split on absences, where the mean 
predicted performance for students with no absences (5\%) was 9.1, and students 
with one or more absences, had a mean predicted performance of 4.6. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{table*}
  \caption{Feature Importance for Random Forests Regression and 
  Gradient Boosting Model}
  \label{tab:freq}
  \begin{tabular}{lllll}
    \toprule
            &           &  & Model & \\ 
    \midrule  
            & Random Forests & & &  Gradient Boosting \\    
    \midrule   
    Predictor           & \% Increase MSE & & Predictor &  Relative Importance \\    
    \midrule
    Mother's Education  &  1.368 &   &      Absences	        &  16.754	\\
    Absences            &  0.884 &   &      Course	            &  11.151   \\
    Area (Urban/Rural)  &  0.592 &   &      Mother's Education  &   7.926	\\
    Higher Education    &  0.575 &   &      Age	                &   7.460   \\   
    Course              &  0.481 &   &      Go Out Friends	    &   5.566   \\ 
    Weekly Alcohol      &  0.473 &   &      Study Time          &   4.618   \\
    Mother's Job        &  0.463 &   &      Health	            &   3.942   \\  
    Father's Education  &  0.399 &   &      Free Time	        &   3.284	\\      
    Go Out Friends      &  0.389 &   &      Family Relations 	&   3.213	\\
    Daily Alcohol       &  0.373 &   &      Weekly Alcohol      &   3.150	\\
    Age                 &  0.370 &   &      Daily Alcohol       &   2.848   \\
    School Support      &  0.347 &   &      Extra Activities    &   2.635   \\  
    Study Time          &  0.321 &   &      School Support  	&   2.550   \\
    Sex                 &  0.318 &   &      Higher Education	&   2.544   \\
    Father's Job        &  0.278 &   &      Father's Job 	    &   2.522   \\     
    Free Time           &  0.272 &   &      Guardian            &   2.124	\\
    Internet Access     &  0.204 &   &      Father's Education  &   2.059   \\   
    Family Relations    &  0.181 &   &      Family Size	        &   1.960   \\
    Extra Activities    &  0.179 &   &      Romantic Relation	&   1.889   \\
    Travel Time         &  0.122 &   &      Internet Access     &   1.875   \\ 
    Guardian            &  0.121 &   &      Sex	        	    &   1.776	\\
    Family Size         &  0.112 &   &      Family Support 	    &   1.762	\\
    Family Support      &  0.103 &   &      Travel Time	        &   1.761   \\
    Health              &  0.097 &   &      Mother's Job    	&   1.757	\\ 
    Romantic Relation   &  0.093 &   &      Paid Extra Courses  &   1.430   \\
    Paid Extra Courses  &  0.075 &   &      Area (Urban/Rural)	&   1.105	\\
    Parents' Relation   &  0.056 &   &      Parents' Relation   &   0.345   \\
    \bottomrule
  \end{tabular}	
\end{table*}
	
	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Random Forests Regression}

The mean squared error (MSE) for the random forests regression was 6.278, 
which indicates better performance for RF than a single decision tree. The 
random forests (RF) algorithm provides feature importance as a model summary; 
for regression, this is measured in terms of percent increase in MSE. The left 
side of Table 6 provides the feature importance for the RF regression sorted 
by percent increase in MSE. The algorithm selected mother's education as the 
most informative feature for predicting student performance (final grade). In 
contrast to the single decision tree, number of absences and area (urban/rural)
were selected as the second and third most important features in the model. 
Plans for higher education and course subject were also among the most 
influential predictor variables in the random forest model, but these
variables were not given as prominent a position as in the single tree. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Gradient Boosting Regression}

The mean squared error (MSE) for the gradient boosted regression tree model  
was 18.124. Feature importance for the gradient boosted regression trees is 
presented on the right side of Table 6. Absences and course subject were 
selected as the two most important features for predicting student performance. 
The algorithm selected mother's education level, student age, going out with 
friends, and weekly study time as the next most informative variables, in 
descending order of importance. Plans for higher education was not selected 
among the most important variables for predicting student performance in 
the gradient boosted model.   

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{DISCUSSION}

The different predictive models identified many of the same variables as 
important for predicting student performance. The linear regression models 
and single regression tree selected course subject as the most informative 
variable for predicting student performance, with students in the Portugese 
course performing better than students in the mathematics course. The models 
differed, however, in the number of variables selected and respective order
of importance assigned to mother's level of education, plans for higher 
education, weekly study time, school educational support, absences, going 
out with friends and involvement in romantic relationships. The general linear 
model selected thirteen predictors variables in the training set, of which, 
only six were significant predictors of student performance in the test set. 
Mother's education level, students' plans for higher education, and weekly 
study time were positively correlated with performance, whereas school support 
and romantic relationships were negatively associated with performance. 
Ridge regression reduced model error by shrinking the coefficient estimates 
towards zero, with a tradeoff of slightly higher bias and risk of underfitting 
the relationships between the features and the target outcome. The lasso model
performed variable selection by forcing the value of seven non-relevant 
coefficient estimates to exactly zero which produced a model based 
on a subset of twenty features. Although the lasso yielded a simpler model 
than the ridge regression, the final model from the multivariate regression 
provided a more parsimonious solution that was more interpretable. It is 
important to note that the predicted value of student performance is 
obtained by the linear combination of all the predictor values in the model.
Ridge regression and the lasso perform better than ordinary least squares when 
working with a very large number of predictors ($\textit{p}>>\textitP{n}$).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In other words, 
one-third of students with plans for higher education failed the course and
over three-
had 
plans to pursue higher education, whereas less than  of students ,  received a failing grade; by contrast, more than
three quarters of students with no plans for higher education received a 
failing grade. 




The linear models showed that substance treatment had the highest
coefficients (followed by heroin use), whereas the tree ensemble methods
indicated that tranquilizer use was the most important feature. Given the 
relatively low rates of prescription opioid and heroin use in the sample, 
additional evidence is needed to clarify questions regarding the importance
of various features for predicting opioid misuse and abuse. 



The simple regression tree model selected course subject as the root node, 
with mother's education, weekly study time, absences, mother's job, and student 
age as the most informative variables for predicting student performance in the 
training set. In the testing set, however, plans for higher education was the 
root node, with mother's education, residence area (rural or urban), course 
subject, and absences selected as the most informative features. Random forests 
regression corrects for overfitting in a single regression tree by constructing
many trees and averaging across the predicted values. Feature importance 
generated by the random forests regression identified mother's education as the 
most informative variable based on the percent change in mean squared error, 
followed by student absences, area, plans for higher education, course subject, 
weekly alcohol consumption, and mother's job as the most informative predictors 
of student performance. The gradient boosting regression is, like random 
forests, an ensemble tree model that generates a large number of trees, each 
new tree correcting for the mistakes of previous trees. The feature importance 
for the gradient boosted model selected student absences as the most important 
feature, followed in descending order of importance by course subject, 
mother's education, student age, going out with friends, and study time, 
among others.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


random forest regression selected Tranquilizers as most informative of
pain reliever misuse, which is consistent with the results of the gradient
boosting model tree ensemble (shown in Table 3). 

A limitation of decision tree models is overfitting to data in the training set. 

previous course failures, course topic, school support, romantic relationship, 
going out with friends, and overall health were negatively correlated with 
student performance, whereas plans for higher education, study time, mother's
education level, internet access, quality of family relations, and father's 
job were positively related to student achievement.


showed that prescription opioid use, misuse, and abuse in this 
sample was higher than use of illicit opioids such as heroin and fentanyl. 
The use of Hydrocodone (Vicodan) was double that of Oxycodone (Oxycodone) 
across almost all age groups. Illicit drug use was highest between the ages 
of 18 to 25. Almost twice as many young adults reported a need for substance 
use treatment, but had not received treatment, compared to the youngest age 
group. Of individuals who reported misusing prescription opioid medications, 
twice as many said they had used heroin than had not (see Figure 1), which is 
consistent with the hypothesis that prescription opioid misuse is associated 
with heroin use. The different learning models provided different estimates 
of the features important for predicting pain reliever misuse and abuse. 


The multiple regression showed multiple features together significantly 
predicted pain reliever abuse, but there may be non-linear trends in the data.
Compared to ridge regression, the lasso performed variable selection, 
indicating that a model with five features (Treatment, Heroin, Cocaine, 
Amphetamine, Any Pain Relievers) explained a significant portion of
variabilty in pain reliever abuse, and adding more factors did not improve
the performance greatly. 




 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Limitations}

A limitation of this study is that variable importance is not a well defined 
concept and lacks a theoretically based quantitative metric \cite{gromping09}. 
In the multivariate linear regression, significance tests are used to select
the variables that significantly predictor the target outcome and non-
significant predictors are excluded from the final model. The t-value provides
a measure of the general effect size of a given variable.

variable selection is performed by 
 and  With random forests regression, variable importance is typically
used for feature selection using
MSE reduction, 

with randome forests 




random forest variable importance measures are a sensible means for variable 
selection in many applications, but are not reliable in situations where potential 
predictor variables vary in their scale of measurement or their number of categories
as in the student performance data

. 
\cite{strohl}

Educational institutions collect large amounts of students data yet much of
this information is protected due to privacy. Responses to anonymous surveys 
are designed to preserve confidentiality and can help to assure`privacy. 


measures of student satisfaction can vary according 
to their perceived usefulness or efficiency of training courses.

This paper reviews LA methodologies, applications, and considers challenges 
and opportunities for implementing LA in education.

A surprising finding is that 

A limitation of the study is that only a small proportion of the sample 
reported having used or misused prescription opioids. It is possible that the 
level of opioid use in the sample was not representative of opioid use in the 
general population. 

The development of LA as a field of 
inquiry have been primarily driven by big data in education and the shift 
toward online learning. 

 The ability to mine large scale data from online 
learning platforms has applications for student success, course design, and 
institutional programs \cite{Lester19}. 

Obtaining reliable information about medication consumption can be difficult 
based on self-reports. Survey data can be biased by under-reporting or by 
minimizing reports of illicit substance use. People may also be reluctant to 
disclose mental health issues or health problems (e.g., STDs, HIV, suicide 
attempts). Another consideration is that,


Alternatively, individuals who...

The results of the present analysis showed that demographic 
characteristics played a relatively...  

Other areas of interest for LA/EDM research include 
increasing (self-)reflection and (self-)awareness, analyzing connections among 
learners, improving feedback and assessment, and recommending educational 
resources \cite{lang17, lester19, papamitsiou14}.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Learning Analytics and EDM}

\subsubsection{Collaboration}

Much LA/EDM research data is collected within a virtual learning 
environment (VLE), learning management system (LMS), or massive open online 
course (MOOC), which can automatically track student participation by login 
frequency, number of resources accessed, time to solve tasks, response times 
to answer questions, number of discussion posts or chat messages between 
participants, questions submitted to instructors. In addition to quantitative 
measures, meaningful analytics systems will include qualitative measures about 
the content or type of contribution (on-topic, evaluative, question). 
Researchers have also studied how affective states (e.g., boredom, 
frustration, confusion, happiness) influence engagement and learning outcomes 
\cite{pardos14}. Merging LMS data with institutional data about student 
performance (i.e., past grades) can provide valuable insights about the 
conditions for successful learning and decision making (Hora, 2019). 


Quantitative data about activities and behavior (e.g., response time, or 
time reflecting on hints) are helpful for modeling engagement or disengagement 
in learning activities, and provide information that allows software to respond 
to individual differences. Discovery and modeling of behaviors during learner 
interactions in a MOOC. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


Learning is a complex phenomenon that is not always directly observable and 
often inferred from student behavior in online learning platforms. Theories of 
learning reveal the importance of collaboration; from the social constructivist 
perspective, knowledge is constructed through interaction with more knowledgeable
partners, parents, teachers, or peers (Vygotsky, 1978). Sociological research
has investigated the characteristic structure of social networks, showing the 
strength of weak social connections (Granovetter, 1973). 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Social network analysis 
(SNA) provides a valuable tool for exploring interactions among learners in 
various contexts. Visualization tools help to reveal connections in large 
datasets and analyze collaboration in online learning platforms (Dawson, 2009). 

Content analysis and automated recommender systems have also been used to guide 
learners toward more personalized learning environments (PLE) (Siemens, 2012, 2013). 

Individual differences in metacognitive (e.g., self-reflection, self-awareness), 
disposition, experience and motivation are influential for developing learning 
relationships (Dawson, et al., 2014; Gašević, et al., 2015). 

Affect and motivation are also influential for predicting performance; notably, 
concentration and 
frustration are significantly correlated with final grades, but boredom and 
confusion were negatively related to performance (Pardos et al., 2013). 
Using data-driven machine learning algorithms on student profiles and data 
about activity within the LMS can facilitate early detection of at-risk 
students \cite{Dekkar09}.  The most 
common reasons for  student disengagement in MOOCs were personal commitments, 
work conflict and course overload (Kizilcec, 2013). 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Predicting Performance} 

The Course Signals program developed at Purdue University 
is one of the most well known platforms for predicting students at-risk of 
falling behind using statistical analysis of LMS data \cite{arnoldPistilli12}. 
In addition to grades, demographic information, academic history, and student 
interaction on the Blackboard LMS were used to track student performance. A 
predictive algorithm was used to calculate likelihood of student success based 
on performance, effort, history, and student characteristics. 

The course signals 
provided students with real-time feedback about their status via the LMS as 
traffic signal indicators (i.e., red=high risk, yellow=moderate risk, green=low 
risk). Instructors enacted interventions for high risk students providing them 
with actionable information about their performance in emails, texts, referrals
to academic advising, or academic resources center, and face to face meetings.
Courses that implemented the Signals program and provided feedback for students
showed an increase in satisfactory grades, decrease in withdrawals, and 
improved retention. Course signals helped to integrate students into the 
university academically in several ways: first, by facilitating contact 
between faculty and students, second, by providing high risk students with 
resources for student success, and third, by using analytics with real time 
data about student performance. in terms of academic success and retention, 
underprepared students in difficult courses using the signals program fared 
better than more well-prepared students in courses that were not using the 
signals program. Furthermore, LA provided faculty with a useful tool for 
identifying struggling students and encouraging them to take corrective actions.  


Analysis of qualitative data, may rely on human judgment, can reveal deeper 
concepts about learning, such as inferring reasoning strategies from interaction 
with a cognitive tutor 
\cite{Fournier11}. Predictive approaches are used also for modeling student 
behavior and assessing functionality in intelligent tutoring systems (ITS)
\cite{penaayala14}. 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Conclusion}

A general conclusion is that... 
The findings...

A general conclusion is that people who reported misusing prescription opioids 
were also likely to have received substance treatment. More than any other 
demographic features, a history of prescription medication use, or illicit drug 
use, both seemed to contribute highly to the abuse of pain reliever medications, 
particularly for those who reported using tranquilizers, heroin, cocaine, or 
amphetamines. The findings suggest that the opioid crisis may be driven by the 
widespread availability of prescription medications. Even for people with no 
previous history of mental health issues, exposure to highly addictive opioid 
medications puts people at risk for drug dependency and addiction. As mentioned 
in the introduction, even for those who have been in drug treatment programs, 
a lack of continuity in treatment can leave many people in recovery at risk 
for relapse or possible overdose as they are released back into environments 
associated with their drug use. The sharp increase in overdose deaths in the 
U.S. due to synthetic opioids (other than methadone) has coincided with the 
increased availability of illicitly manufactured fentanyl \cite{nida17}. 
Because the dosage levels and potency of illicit opioids are largely unknown, 
there is greater risk of drug overdose death. Recent findings suggest the 
opioid overdose epidemic is getting worse, and requires urgent action to prevent 
opioid abuse, addiction, and death. The findings reported here seek to raise 
awareness about the risk factors for prescription opioid addiction for patients 
and health care providers in order to help reduce opioid overdose deaths. 

Additional research is needed to understand the relationships among variables 
that predict student performance. The findings may inform decision making and 

policy efforts 
to address the opioid crisis and reduce the risk of overdose death. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{unsrt} %%ACM-Reference-Format%%
\bibliography{report} 

\end{document} 
